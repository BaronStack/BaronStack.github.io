{"title":"2018-01-21","slug":"2018-01-21","date":"2018-01-21T13:43:30.000Z","updated":"2018-02-22T12:54:00.000Z","comments":true,"path":"api/articles/2018-01-21.json","photos":[],"link":"","excerpt":"废话不多说，先上一个关于人工智能以及深度学习入门的一个大佬的博客链接莫烦，这两天一直在看他的教学视频，真的是受益匪浅。","covers":null,"content":"<p>废话不多说，先上一个关于人工智能以及深度学习入门的一个大佬的博客链接<a href=\"https://morvanzhou.github.io/\" target=\"_blank\" rel=\"noopener\">莫烦</a>，这两天一直在看他的教学视频，真的是受益匪浅。<a id=\"more\"></a></p>\n<p>我从他的视频讲解中了解到的一些理论知识如下：</p>\n<ul>\n<li>什么是神经网络</li>\n<li>什么是梯度下降</li>\n<li>什么是激励函数</li>\n</ul>\n<p>这一些基础且重要的概念，让我在实践过程中对神经网络有了更深一步的了解</p>\n<p><strong>神经网络（NEURAL NETS）</strong> ：计算机中的神经网络是模拟人的神经网络的形成和功能的一种基于统计学、数学、计算机科学的模型。它可以对输入和输出数据之间的关系进行建模，从而产生特定且有用的概率数据。当然，神经网络通过很多层的数据处理，将输入的大量数据通过不断的反馈优化，降低其与真实值之间的差距，产生一个较高概率的结果。</p>\n<p><strong>梯度下降 (GRADIENT DESCENT)</strong> ：神经网络在进行数据预测的时候会有一个误差方程，来降低真实结果与预测结果之间的误差，这个降低误差的过程就叫做梯度下降。当然Tensorflow中所拥有的API可以进类似于梯度下降的功能！</p>\n<p><strong>激励函数（ACTIVATION FUNCTION）</strong> ：为了解决日常生活中不能用线性方程解决的问题（一般神经网络中数值关系理想状态下都是线性的，但是理想是美好的，现实是残酷的，那么就需要激励函数将理想中的数值关系强行掰弯），从而使得训练的输出结果拥有非线性的关系，提升预测结果概率。（TENSORFLOW 官网有大量的激励函数，在神经网CNN一般使用relu,在神经网络RNN常使用relu和tanh）</p>\n<p>一些实际的Tensor flow程序可以参考莫烦的github，而且他的视频对程序的讲解很详细，一定要耐心琢磨。</p>\n","categories":[{"name":"日记","slug":"life","count":29,"path":"api/categories/life.json"}],"tags":[]}