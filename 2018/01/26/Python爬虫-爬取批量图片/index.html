<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Mr.张">
  <!-- Open Graph Data -->
  <meta property="og:title" content="Python爬虫 爬取批量图片"/>
  <meta property="og:description" content="" />
  <meta property="og:site_name" content="那一刻 风情万种"/>
  <meta property="og:type" content="article" />
  <meta property="og:image" content="http://yoursite.com"/>
  
    <link rel="alternate" href="/atom.xml" title="那一刻 风情万种" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>那一刻 风情万种</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.dark.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/img/default-banner-dark.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">Python爬虫 爬取批量图片</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="/categories">
                  
                  categories
                  
                </a>
              </li>
            
              <li>
                <a href="/tags">
                  
                  tags
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/BaronStack">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="/2689496754@qq.com">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
          <span id="busuanzi_container_site_uv">
          本站访客数<span id="busuanzi_value_site_uv"></span>人次
          </span>
            <!-- Author -->
            <span class="author info">By Mr.张</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2018-01-26</span>
            <span class="time">19:40:44</span>
          </span>
      </div>
        <!-- Tags -->
        <!-- Post Main Content -->
        <div class="post-content">
          <p>本部分的主要代码在<br><a href="https://github.com/BaronStack/Python-Reptitle/tree/master/reptitle_trying" target="_blank" rel="noopener">爬取批量图片到本地</a></p>
<h4 id="如何用python-爬取图片网站的图片"><a href="#如何用python-爬取图片网站的图片" class="headerlink" title="如何用python 爬取图片网站的图片"></a>如何用python 爬取图片网站的图片</h4><blockquote>
<p>这里的图片是按页显示的，所以它爬取的是每一页的图片</p>
</blockquote>
<ul>
<li>获取网页链接</li>
<li>利用正则提取以页为单位的html内容</li>
<li>获取每一页中图片的存储链接</li>
<li>利用循环下载保存<a id="more"></a></li>
</ul>
<p>导入的包如下：<br><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment"># 方便提取标签中的内容</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment"># 向网页发送请求的包，获取网页内容</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment"># 正则表达式的包</span></span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen <span class="comment"># 也是用来获取网页内容</span></span><br><span class="line"><span class="keyword">import</span> os <span class="comment"># 文件目录操作</span></span><br></pre></td></tr></table></figure></p>
<h5 id="获取网页链接，利用正则提取以页为单位的html链接"><a href="#获取网页链接，利用正则提取以页为单位的html链接" class="headerlink" title="获取网页链接，利用正则提取以页为单位的html链接"></a>获取网页链接，利用正则提取以页为单位的html链接</h5><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里也可以用语句 html = requests.get("http://www.ivsky.com/tupian/xuejing_t36/index_2.html").text来获取网页内容</span></span><br><span class="line"><span class="attr">html</span> = urlopen(<span class="string">"http://www.ivsky.com/tupian/xuejing_t36/index_2.html"</span>).read().decode(<span class="string">'utf-8'</span>) </span><br><span class="line"><span class="comment">#利用BeautifulSoup对html进行解析，从而可以获取网页的节点属性</span></span><br><span class="line"><span class="attr">soup</span> = BeautifulSoup(html, features=<span class="string">'lxml'</span>)</span><br><span class="line"><span class="comment">#找到以'panelist'为class的div标签的内容（这里存储的不同页面的html链接）</span></span><br><span class="line"><span class="attr">img_links</span> = soup.find_all(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">'pagelist'</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用正则表达式，将标签中的链接取出来，形成列表。这里可以打开链接</span></span><br><span class="line"><span class="attr">course_links</span> = soup.find_all(<span class="string">'a'</span>, &#123;<span class="string">'href'</span>: re.compile(<span class="string">'/tupian/.*index_.\.html$'</span>)&#125;)</span><br><span class="line"><span class="comment">#这里的链接是没有http://跳转的，所以给其中每个链接都加上这样的跳转</span></span><br><span class="line"><span class="attr">resultURL</span> = [<span class="string">"%s%s"</span> %(<span class="string">'http://www.ivsky.com'</span>,links[<span class="string">'href'</span>]) for links in course_links]</span><br></pre></td></tr></table></figure>
<h5 id="获取每一页中图片的存储链接"><a href="#获取每一页中图片的存储链接" class="headerlink" title="获取每一页中图片的存储链接"></a>获取每一页中图片的存储链接</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#取得当前页面的URL</span><br><span class="line"><span class="selector-tag">html</span> = requests.get(URL).text</span><br><span class="line">#解析</span><br><span class="line">soup = BeautifulSoup(<span class="selector-tag">html</span>, <span class="string">'lxml'</span>)</span><br><span class="line">#找到以il_img为class的div标签</span><br><span class="line">img_ul = soup.find_all(<span class="string">'div'</span>, &#123;<span class="string">'class'</span>: <span class="string">"il_img"</span>&#125;)</span><br><span class="line">#查看找到的区域数量</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(len(img_ul)</span></span>)</span><br></pre></td></tr></table></figure>
<p>这里在利用浏览器的检查元素进行查找，在找的过程中尽可能将当前页面图片进行归类分析，找出其共有的标签属性，方便将所有的图片进行爬取</p>
<h5 id="利用循环下载保存"><a href="#利用循环下载保存" class="headerlink" title="利用循环下载保存"></a>利用循环下载保存</h5><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">os.makedirs(<span class="string">'./img/'</span>, exist_ok=True)<span class="comment">#创建保存的文件夹及存储目录，可以自行更改</span></span><br><span class="line">    <span class="keyword">for</span> ul <span class="keyword">in</span> img_ul:</span><br><span class="line">        imgs = ul.find_all(<span class="string">'img'</span>)<span class="comment">#找到 img标签</span></span><br><span class="line">        <span class="keyword">for</span> img <span class="keyword">in</span> imgs:</span><br><span class="line">            url = img[<span class="string">'src'</span>] <span class="comment">#找到src标签，因为其后跟着图片链接</span></span><br><span class="line">            r = requests.<span class="built_in">get</span>(url, stream=True)</span><br><span class="line">            image_name = url.<span class="built_in">split</span>(<span class="string">'/'</span>)[<span class="number">-1</span>] <span class="comment">#图片以最后一个'／'右边的内容明名，也可以自行命名</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'./img/%s'</span> % image_name, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content(chunk_size=<span class="number">128</span>): <span class="comment">#将图片分块以数据流的方式直接写入到本地</span></span><br><span class="line">                    f.<span class="built_in">write</span>(chunk)</span><br><span class="line">            print(<span class="string">'Saved %s'</span> % image_name) <span class="comment">#打印保存的进度</span></span><br></pre></td></tr></table></figure>
<p>最后看看我们的结果：</p>
<p><img src="/images/python/scrap_images.png" alt="运行结果"></p>
<p><img src="/images/python/scrap_images_d.png" alt="保存结果"></p>
<p>所以<strong>妈妈再也不用担心我没有素材啦</strong></p>

        </div>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
          <span id="busuanzi_container_page_uv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span>
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

